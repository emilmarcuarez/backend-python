# services/malware.py  — endurecido
import os, re, time, base64, math, json, xml.etree.ElementTree as ET
from urllib.parse import urljoin, urlparse
from typing import List, Tuple, Dict

import requests
from bs4 import BeautifulSoup

# Playwright opcional (degrada a requests si falla)
try:
    from playwright.sync_api import sync_playwright
    _HAS_PW = True
except Exception:
    _HAS_PW = False

UA = {"User-Agent": "IDEI-Auditor/1.1 (+analisis.ideidev.com)"}
TIMEOUT = (8, 25)

# ================= Heurísticas ampliadas =================

# Palabras clave ES/EN: gambling, pharma, adult, crypto, loans, piratería, etc.
SUS_KEYWORDS = [
    # Gambling (ES/EN) - Ampliado
    r"\bcasino(s)?\b", r"\bruleta\b", r"\btragamonedas\b", r"\btragaperras\b",
    r"\bslots?\b", r"\bblackjack\b", r"\bbacara?t\b", r"\bapuestas?\b",
    r"\bbono(s)?\b", r"\bgiros\b", r"\bfree\s*spins?\b", r"\bjuego(s)?\b",
    r"\bazar\b", r"\bganar\s*dinero\b", r"\bjackpot\b", r"\bbet\b", r"\bgambling\b",
    r"\blotería\b", r"\bloteria\b", r"\bnúmeros?\s*de\s*lotería\b", r"\bcomprobar\s*lotería\b",
    r"\bdescargar\s*juego\b", r"\bjuego\s*de\s*ruleta\b", r"\bcomo\s*ganar\s*siempre\b",
    r"\bentrada\s*casino\b", r"\bmáquinas?\s*tragamonedas\b", r"\bjuegos?\s*de\s*casino\b",
    r"\bsuerte\s*juegos?\s*de\s*azar\b", r"\bcomprobar\s*lotería\s*nacional\b",
    # Pharma - Ampliado
    r"\bviagra\b", r"\bcialis\b", r"\blevitra\b", r"\bphentermine\b",
    r"\bpildoras?\b", r"\bpastillas?\b", r"\bpoten(ci|cy)\b", r"\bpharmacy\b",
    r"\bpills\b", r"\bweight\s*loss\b", r"\bdiet\b",
    # Adult
    r"\bporno?\b", r"\bxxx\b", r"\berotic\b", r"\bescort(s)?\b",
    # Crypto/Scam - Ampliado
    r"\bcrypto\b", r"\bbitcoin\b", r"\beth(ereum)?\b", r"\bforex\b",
    r"\binvest(ment)?\b", r"\bprofit\b", r"\breturns?\b", r"\bloan\b",
    r"\bcredit\b", r"\bdebt\b", r"\bmortgage\b", r"\binsurance\b",
    # Otros spam SEO comunes - Ampliado
    r"\bdescargas? (gratis|free)\b", r"\bserial(es)?\b",
    r"\bcrack(eado)?\b", r"\bkeygen\b", r"\blicencia gratis\b",
    r"\bclick\s*here\b", r"\bfree\s*money\b", r"\bwin\s*now\b", r"\bguaranteed\b",
    r"\bno\s*risk\b", r"\blimited\s*time\b", r"\bact\s*now\b", r"\burgent\b",
    r"\bsecret\b", r"\bhidden\b",
    # Patrones específicos del sitio mencionado
    r"\bbuscador\s*de\s*números?\s*de\s*lotería\b", r"\bdesbloquea\s*un\s*nivel\b",
    r"\bclímax\s*de\s*sesión\b", r"\bgrandes\s*ganancias\b", r"\bpagos\s*sustanciales\b",
    r"\bcenturión\b", r"\bplata\b", r"\boro\b", r"\bplatino\b", r"\bultimate\b",
    r"\bconstantemente\s*se\s*agregan\b", r"\bsuper15\s*stars\b", r"\bblazing\s*bullfrog\b",
    r"\bcodex\s*of\s*fortune\b", r"\bbaraja\s*de\s*poker\b", r"\bbono\s*de\s*regalo\b",
    r"\bdinero\s*real\b", r"\bsitios?\s*web\s*de\s*bingo\b", r"\bcaracterísticas?\s*sociales\b",
    r"\bprogramas?\s*de\s*logros\b", r"\bcomunicarse\s*entre\s*sí\b", r"\brecompensas\b",
    r"\bentrada\s*casino\s*enjoy\b", r"\bpucon\b", r"\bcopia\s*de\s*los\s*datos\b",
    r"\bformato\s*legible\b", r"\belectrónicamente\b", r"\btragamonedas\s*entretenidas\b",
    r"\bentretenimiento\s*decente\b", r"\bmayores\s*posibilidades\s*de\s*ganar\b",
    r"\bblood\s*suckers\b", r"\bcomprobar\s*lotería\s*nacional\b", r"\bdía\s*del\s*padre\b",
    r"\bmáquinas?\s*tragamonedas\s*gratis\b", r"\bpara\s*jugar\b", r"\bjuegos?\s*de\s*casino\s*gratis\b",
    r"\btragamonedas\s*gratis\b", r"\bmujeres\s*suelen\s*constituir\b", r"\bpequeño\s*porcentaje\b",
    r"\bcampos?\s*de\s*torneos?\s*de\s*póquer\b", r"\bsituación\s*no\s*parece\b",
    r"\bhaber\s*cambiado\b", r"\bsuerte\s*juegos?\s*de\s*azar\b",
]

# Firmas populares de JS malicioso/obfuscado
SIGNS_JS = [
    r"eval\s*\(", r"Function\s*\(", r"document\.write\s*\(", r"atob\s*\(",
    r"unescape\s*\(", r"fromCharCode\s*\(", r"setTimeout\s*\(.{0,120}eval\s*\(",
    r"eval\(function\(p,a,c,k,e,d\)",  # Packer clásico
    r"new Function\s*\(",
    r"window\.onload\s*=",
    r"\.replace\s*\(.{0,80}/.*\/[gimuy]{0,5}\)",  # replaces con regex sospechosos
    r"\\x[0-9a-fA-F]{2}",  # hex escapado masivo
]

# Estilos / artefactos ocultos
HIDDEN_STYLE = [
    r"display\s*:\s*none", r"visibility\s*:\s*hidden",
    r"opacity\s*:\s*0(?:\.0+)?\b", r"font-size\s*:\s*0\b",
    r"position\s*:\s*absolute;?\s*left\s*:\s*-\d+px",  # fuera de viewport
]

# Dominios/patrones externos a vigilar (denylist corta — evita falsos positivos)
SUS_EXTERNAL_PATTERNS = [
    r"(?:fast|best|super|ultra)[-]?(?:cdn|js|script)\d*\.",
    r"-(?:cdn|js)\.top\b",
    r"\.(?:xyz|top|gq|cn|ru)(?:/|$)",
    r"(?:bet|casino|slot)s?\.",
]

# iFrames y meta refresh
IFRAME_SUS = [
    r"<iframe[^>]+width\s*=\s*['\"]?1['\"]?[^>]*height\s*=\s*['\"]?1['\"]?[^>]*>",
    r"<iframe[^>]+style=['\"][^>]*display\s*:\s*none[^>]*['\"][^>]*>",
]
META_REFRESH = r'<meta[^>]+http-equiv=["\']refresh["\'][^>]+content=["\']\s*\d+\s*;\s*url='

# ================= Utilidades =================

def same_host(u0, u1):
    try:
        h0 = (urlparse(u0).hostname or "").lower()
        h1 = (urlparse(u1).hostname or "").lower()
        return h0 and h1 and h0 == h1
    except Exception:
        return False

def _fetch(url) -> str:
    try:
        r = requests.get(url, headers=UA, timeout=TIMEOUT, allow_redirects=True)
        if r.status_code == 200:
            return r.text or ""
    except Exception:
        pass
    return ""

def entropy(s: str) -> float:
    # Entropía Shannon simple sobre bytes
    if not s:
        return 0.0
    import collections, math
    counts = collections.Counter(s)
    l = float(len(s))
    return -sum((c/l) * math.log2(c/l) for c in counts.values())

def collect_links(base_url, html, limit=120):
    out = []
    soup = BeautifulSoup(html or "", "lxml")
    for a in soup.find_all("a", href=True):
        href = a["href"].strip()
        if href.startswith("#"):
            continue
        url = urljoin(base_url, href)
        if same_host(base_url, url):
            out.append(url.split("#")[0])
    # prioriza sospechosas por keywords
    def score(u: str):
        s = 0
        for kw in SUS_KEYWORDS:
            if re.search(kw, u, flags=re.I):
                s += 5
        return -s, len(u)
    out = sorted(list(dict.fromkeys(out)))
    out = sorted(out, key=score)
    return out[:limit]

def parse_sitemap(xml_text: str) -> List[str]:
    out = []
    if not xml_text:
        return out
    try:
        tree = ET.fromstring(xml_text)
        ns = {"sm": "http://www.sitemaps.org/schemas/sitemap/0.9"}
        for e in tree.findall(".//sm:loc", ns):
            if e.text:
                out.append(e.text.strip())
        return out
    except Exception:
        # Fallback por regex
        locs = re.findall(r"<loc>(.*?)</loc>", xml_text, re.I)
        return [l.strip() for l in locs]

def discover_urls(base_url, limit=500) -> List[str]:
    """
    Descubre URLs con sitemap(s) (wp-sitemap.xml, sitemap.xml, sitemap_index.xml),
    y también usando WP REST Search para términos “calientes”.
    """
    urls = []
    bases = [
        "/wp-sitemap.xml",          # WP core
        "/sitemap.xml",             # genérico
        "/sitemap_index.xml",       # Yoast / RankMath
        "/post-sitemap.xml",        # sitemaps hijos
        "/page-sitemap.xml",
        "/category-sitemap.xml",
    ]
    host = urlparse(base_url).scheme + "://" + (urlparse(base_url).hostname or "")
    seen = set()
    for b in bases:
        xml = _fetch(urljoin(host, b))
        for u in parse_sitemap(xml):
            if same_host(base_url, u) and u not in seen:
                seen.add(u)
                urls.append(u)

    # REST Search de WP para múltiples términos (reduce ruido) - Ampliado
    try:
        terms = [
            "casino", "slot", "ruleta", "apuesta", "viagra", "cialis", "xxx", "crypto", "bitcoin", "forex", "descarga", "crack",
            "lotería", "lotería nacional", "números de lotería", "comprobar lotería", "juego", "azar", "ganar dinero",
            "tragamonedas", "bingo", "poker", "blackjack", "bono", "jackpot", "bet", "gambling", "apuestas",
            "descargar juego", "juego de ruleta", "como ganar siempre", "entrada casino", "máquinas tragamonedas",
            "juegos de casino", "suerte juegos de azar", "comprobar lotería nacional", "buscador de números",
            "desbloquea un nivel", "clímax de sesión", "grandes ganancias", "pagos sustanciales", "centurión",
            "plata", "oro", "platino", "ultimate", "constantemente se agregan", "super15 stars", "blazing bullfrog",
            "codex of fortune", "baraja de poker", "bono de regalo", "dinero real", "sitios web de bingo",
            "características sociales", "programas de logros", "comunicarse entre sí", "recompensas",
            "entrada casino enjoy", "pucon", "copia de los datos", "formato legible", "electrónicamente",
            "tragamonedas entretenidas", "entretenimiento decente", "mayores posibilidades de ganar",
            "blood suckers", "día del padre", "máquinas tragamonedas gratis", "para jugar",
            "juegos de casino gratis", "tragamonedas gratis", "mujeres suelen constituir", "pequeño porcentaje",
            "campos de torneos de póquer", "situación no parece", "haber cambiado", "suerte juegos de azar"
        ]
        for t in terms:
            q = requests.get(urljoin(base_url, "/wp-json/wp/v2/search"),
                             params={"search": t, "per_page": 50},
                             headers=UA, timeout=(6, 12))
            if q.status_code == 200:
                for item in q.json():
                    link = item.get("url") or item.get("link")
                    if link and same_host(base_url, link) and link not in seen:
                        seen.add(link); urls.append(link)
    except Exception:
        pass

    return urls[:limit]

def render_dom(url) -> Tuple[str, str, List[str]]:
    """
    Devuelve (html_raw, html_dom, scripts_externos)
    """
    html_raw, html_dom, externals = "", "", []
    try:
        r = requests.get(url, headers=UA, timeout=TIMEOUT)
        html_raw = r.text or ""
    except Exception:
        pass

    if _HAS_PW:
        try:
            with sync_playwright() as p:
                b = p.chromium.launch(headless=True, args=["--no-sandbox"])
                c = b.new_context(ignore_https_errors=True, user_agent=UA["User-Agent"])
                page = c.new_page()
                page.goto(url, wait_until="networkidle", timeout=35000)
                # Espera breve adicional para late-injections
                page.wait_for_timeout(500)
                html_dom = page.content() or ""
                externals = page.evaluate("""() => Array.from(document.scripts)
                    .filter(s => s.src).map(s => s.src)""") or []
                b.close()
        except Exception:
            # degrada
            pass

    return html_raw, html_dom, externals

def decode_base64_chunks(text: str) -> List[str]:
    samples = []
    for m in re.finditer(r"(?<![A-Za-z0-9+/=])([A-Za-z0-9+/]{100,}={0,2})(?![A-Za-z0-9+/=])", text):
        blob = m.group(1)
        try:
            dec = base64.b64decode(blob + "==", validate=False)
            if dec and len(dec) >= 80:
                samples.append(dec.decode("utf-8", "ignore")[:800])
        except Exception:
            pass
        if len(samples) >= 5:
            break
    return samples

def find_indicators(html_text: str) -> Tuple[List[str], List[str]]:
    findings = []
    text = html_text or ""

    # JS malicioso/obfuscado
    for sig in SIGNS_JS:
        if re.search(sig, text, flags=re.I | re.S):
            findings.append(f"js:{sig}")

    # CSS oculto
    for hs in HIDDEN_STYLE:
        if re.search(hs, text, flags=re.I):
            findings.append(f"hidden:{hs}")

    # Keywords - Más estricto
    kw_hits = 0
    for kw in SUS_KEYWORDS:
        if re.search(kw, text, flags=re.I):
            kw_hits += 1
    if kw_hits >= 1:  # Cambiado de 2 a 1 para ser más estricto
        findings.append(f"keywords:{kw_hits}")

    # iFrames y meta refresh
    for fr in IFRAME_SUS:
        if re.search(fr, text, flags=re.I):
            findings.append("iframe:hidden")
            break
    if re.search(META_REFRESH, text, flags=re.I):
        findings.append("meta:refresh")

    # Externals raros
    ext_sus = 0
    for pat in SUS_EXTERNAL_PATTERNS:
        if re.search(pat, text, flags=re.I):
            ext_sus += 1
    if ext_sus:
        findings.append(f"externals:{ext_sus}")

    # Entropía alta en scripts grandes (trozos > 600 chars)
    chunks = re.findall(r"<script[^>]*>(.{600,})</script>", text, re.I | re.S)
    for ch in chunks[:10]:
        if entropy(ch) >= 4.2:  # alto
            findings.append("entropy:high")
            break

    # Snippets: scripts/iframes y decodificados base64
    snippets = []
    for m in re.finditer(r"(?:<script[^>]*>.*?</script>)|(?:<iframe[^>]*>)", text, re.I | re.S):
        frag = text[m.start():m.end()]
        snippets.append(frag[:800])
        if len(snippets) >= 8:
            break

    for dec in decode_base64_chunks(text):
        snippets.append(dec[:800])
        if len(snippets) >= 12:
            break

    return findings, snippets

def scan_site_malware(start_url: str, max_pages=80, per_url_budget=0.2) -> Dict:
    """
    Crawler + DOM render + descubrimiento por sitemap y WP REST.
    Devuelve:
      {
        infected: bool,
        severity: "critical"|"high"|"medium"|"low"|None,
        urls: [ { url, findings_dom[], findings_raw[], external_scripts[], snippets[] }, ... ],
        summary: { suspected_urls[], counts: {...} }
      }
    """
    result = {"infected": False, "severity": None, "urls": [], "summary": {}}
    visited = set()

    # 0) Home + links
    home_html = _fetch(start_url)
    seed = [start_url] + collect_links(start_url, home_html, limit=min(40, max_pages//2))

    # 1) Sitemaps + REST Search
    more = []
    try:
        more = discover_urls(start_url, limit=500)
    except Exception:
        more = []
    # dedup y prioriza sospechosas
    all_urls = []
    seen = set()
    for u in seed + more:
        if u not in seen and same_host(start_url, u):
            seen.add(u); all_urls.append(u)
    def u_score(u: str):
        s = 0
        for kw in SUS_KEYWORDS:
            if re.search(kw, u, flags=re.I): s += 5
        return -s, len(u)
    all_urls = sorted(all_urls, key=u_score)[:max_pages]

    suspicious_hits = []
    counts = {"dom_hits":0, "raw_hits":0, "externals":0, "hidden":0, "keywords":0, "entropy":0, "meta":0}

    for u in all_urls:
        if u in visited: 
            continue
        visited.add(u)

        html_raw, html_dom, ext_js = render_dom(u)

        f_dom, sn_dom = find_indicators(html_dom)
        f_raw, _      = find_indicators(html_raw)

        entry = {
            "url": u,
            "findings_dom": f_dom,
            "findings_raw": f_raw,
            "external_scripts": ext_js[:80],
            "snippets": (sn_dom or [])[:6],
        }
        result["urls"].append(entry)

        # Contabiliza
        if f_dom: counts["dom_hits"] += 1
        if f_raw: counts["raw_hits"] += 1
        if any(x.startswith("externals:") for x in (f_dom+f_raw)): counts["externals"] += 1
        if any(x.startswith("hidden:") for x in (f_dom+f_raw)): counts["hidden"] += 1
        if any(x.startswith("keywords:") for x in (f_dom+f_raw)): counts["keywords"] += 1
        if any(x.startswith("entropy:") for x in (f_dom+f_raw)): counts["entropy"] += 1
        if any(x.startswith("meta:refresh") for x in (f_dom+f_raw)): counts["meta"] += 1

        if f_dom or f_raw:
            suspicious_hits.append(u)

        time.sleep(per_url_budget)

    result["summary"]["suspected_urls"] = suspicious_hits
    result["summary"]["counts"] = counts

    # Severidad - Más estricto
    score = 0
    score += 4 * min(counts["dom_hits"], 5)  # Aumentado de 3 a 4
    score += 3 * min(counts["raw_hits"], 5)  # Aumentado de 2 a 3
    score += 3 * counts["hidden"]            # Aumentado de 2 a 3
    score += 3 * counts["externals"]         # Aumentado de 2 a 3
    score += 2 * counts["keywords"]          # Aumentado de 1 a 2
    score += 3 * counts["entropy"]           # Aumentado de 2 a 3
    score += 3 * counts["meta"]              # Aumentado de 2 a 3
    # umbrales más estrictos
    if score >= 8:   # Bajado de 12 a 8
        sev = "critical"
    elif score >= 5: # Bajado de 8 a 5
        sev = "high"
    elif score >= 3: # Bajado de 4 a 3
        sev = "medium"
    elif score >= 1: # Bajado de 2 a 1
        sev = "low"
    else:
        sev = None

    result["infected"] = bool(sev)
    result["severity"] = sev
    return result
