# services/malware.py
import os, re, time, base64, hashlib, requests
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup
from playwright.sync_api import sync_playwright

UA = {"User-Agent": "IDEI-Auditor/1.0"}
TIMEOUT = (6, 25)

# Palabras sospechosas (spam casino, hack SEO común en ES)
SUS_KEYWORDS = [
    r"\bcasino\b", r"\bruleta\b", r"\btragamonedas\b", r"\bbono\b",
    r"\bapuesta\b", r"\bslots?\b", r"\bcasino online\b",
]

# Firmas “rápidas” de JS malicioso/inyectado
SIGNS_JS = [
    r"eval\(", r"Function\(", r"document\.write\(", r"atob\(", r"unescape\(", r"fromCharCode\(",
    r"location\.href\s*=", r"window\.onload\s*=", r"setInterval\(", r"setTimeout\(.{0,80}eval\(",
    r"[a-zA-Z0-9_]{50,}={1,2}[a-zA-Z0-9+/]{50,}={0,2}",  # blobs base64 largos
    r"\\x[0-9a-fA-F]{2}",  # escaped hex
]

# Estilos ocultos
HIDDEN_STYLE = [r"display\s*:\s*none", r"visibility\s*:\s*hidden", r"opacity\s*:\s*0", r"font-size\s*:\s*0"]

def same_host(u0, u1):
    try:
        h0 = urlparse(u0).hostname
        h1 = urlparse(u1).hostname
        return (h0 and h1) and (h0.lower() == h1.lower())
    except Exception:
        return False

def collect_links(base_url, html, limit=100):
    out = []
    soup = BeautifulSoup(html or "", "lxml")
    for a in soup.find_all("a", href=True):
        href = a["href"].strip()
        if href.startswith("#"): continue
        url = urljoin(base_url, href)
        if same_host(base_url, url):
            out.append(url.split("#")[0])
    # prioriza sospechosas
    def score(u: str):
        s = 0
        for kw in SUS_KEYWORDS:
            if re.search(kw, u, flags=re.I): s += 5
        return -s, len(u)  # más score → primero
    out = sorted(list(dict.fromkeys(out)))  # únicos
    out = sorted(out, key=score)
    return out[:limit]

def render_dom(url):
    """
    Devuelve (html_raw, html_dom, scripts_externos)
    """
    html_raw, html_dom, externals = "", "", []
    try:
        r = requests.get(url, headers=UA, timeout=TIMEOUT)
        html_raw = r.text or ""
    except Exception:
        pass

    try:
        with sync_playwright() as p:
            b = p.chromium.launch(headless=True)
            c = b.new_context(ignore_https_errors=True, user_agent=UA["User-Agent"])
            page = c.new_page()
            page.goto(url, wait_until="networkidle", timeout=30000)
            html_dom = page.content() or ""
            # scripts externos
            ext = page.evaluate("""() => Array.from(document.scripts)
              .filter(s => s.src)
              .map(s => s.src)""")
            externals = ext or []
            b.close()
    except Exception:
        pass

    return html_raw, html_dom, externals

def find_indicators(html_text):
    iocs = []
    findings = []
    text = html_text or ""
    # JS sospechoso
    for sig in SIGNS_JS:
        if re.search(sig, text, flags=re.I|re.S):
            findings.append(f"match:{sig}")

    # CSS oculto
    for hs in HIDDEN_STYLE:
        if re.search(hs, text, flags=re.I):
            findings.append(f"hidden_css:{hs}")

    # Palabras casino
    for kw in SUS_KEYWORDS:
        if re.search(kw, text, flags=re.I):
            findings.append(f"keyword:{kw}")

    # Extrae snippets cortos de evidencia
    snippets = []
    for m in re.finditer(r"(?:<script[^>]*>.*?</script>)|(?:<iframe[^>]*>)", text, re.I|re.S):
        frag = text[m.start():m.end()]
        snippets.append(frag[:500])

    # recorta lista
    if len(snippets) > 10:
        snippets = snippets[:10] + ["…"]

    return findings, snippets

def scan_site_malware(start_url, max_pages=50, per_url_budget=0.5):
    """
    Crawler sencillo + render: devuelve dict con infected, urls y evidencias.
    """
    result = {
        "infected": False,
        "urls": [],
        "summary": {},
    }
    visited = set()
    queue = [start_url]

    # 1) Render home para sacar links
    try:
        r = requests.get(start_url, headers=UA, timeout=TIMEOUT)
        start_html = r.text or ""
    except Exception:
        start_html = ""

    links = collect_links(start_url, start_html, limit=max_pages)
    # incluye la home al principio
    urls = [start_url] + [u for u in links if u != start_url]
    urls = urls[:max_pages]

    suspicious_hits = []

    for u in urls:
        if u in visited: continue
        visited.add(u)
        html_raw, html_dom, ext_js = render_dom(u)

        # Busca indicadores en DOM renderizado primero (más fiable)
        findings_dom, snippets_dom = find_indicators(html_dom)
        findings_raw, _ = find_indicators(html_raw)

        # Registra
        entry = {
            "url": u,
            "findings_dom": findings_dom,
            "findings_raw": findings_raw,
            "external_scripts": ext_js[:50],
            "snippets": snippets_dom,
        }
        result["urls"].append(entry)

        # Heurística: si hay “casino/ruleta/…” o firmas JS → marca sospechoso
        if findings_dom or findings_raw:
            suspicious_hits.append(u)

        # Pequeña pausa para no sobrecargar
        time.sleep(per_url_budget)

    result["summary"]["suspected_urls"] = suspicious_hits
    result["infected"] = len(suspicious_hits) > 0
    return result
